{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math; import os\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam\n",
    "from gym import spaces \n",
    "import numpy as np \n",
    "from IPython.display import clear_output\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "import gym\n",
    "from gym import spaces; import random\n",
    "import numpy as np; import pandas as pd \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import _tree\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "hidden_size = [1000,1600,1000]\n",
    "lr = 0.0001\n",
    "batch_size = 144*1\n",
    "tau = 0.005\n",
    "LOG_SIG_MAX = 2\n",
    "LOG_SIG_MIN = -20\n",
    "epsilon = 1e-6\n",
    "\n",
    "args= {}\n",
    "args['alpha'] = 0.2\n",
    "args['gamma'] = 0.9995\n",
    "args['tau'] = 0.005\n",
    "args['lr'] = 0.00003\n",
    "args['batch_size'] = 144*10\n",
    "args['num_steps'] = 1000001\n",
    "args['hidden_size'] = [1000,1600,1000]\n",
    "args['updates_per_step'] = 5\n",
    "args['start_steps'] = 10000\n",
    "args['replay_size'] = 144*2000\n",
    "args['policy'] = 'Gaussian'\n",
    "args['automatic_entropy_tuning'] = False\n",
    "args['target_update_interval'] = 5\n",
    "args['cuda'] = 'store_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cool_stp(Temp_mean_p0,Temp_mean_m1,sen_hou,rh,rtp_2):\n",
    "    if Temp_mean_p0 <= 24.427:\n",
    "        if rtp_2 <= 0.15:\n",
    "            if rh <= 55.0:\n",
    "                if Temp_mean_p0 <= 20.583:\n",
    "                    return 23.953\n",
    "                else:\n",
    "                    return 25.243\n",
    "            else:\n",
    "                if sen_hou <= 6.0:\n",
    "                    return 27.798\n",
    "                else:\n",
    "                    return 25.333\n",
    "        else:\n",
    "            if Temp_mean_p0 <= 23.315:\n",
    "                if Temp_mean_m1 <= 26.08:\n",
    "                    return 24.535\n",
    "                else:\n",
    "                    return 23.603\n",
    "            else:\n",
    "                if Temp_mean_m1 <= 26.054:\n",
    "                    return 23.351\n",
    "                else:\n",
    "                    return 21.897\n",
    "    else:\n",
    "        if sen_hou <= 20.4:\n",
    "            if Temp_mean_p0 <= 25.561:\n",
    "                if sen_hou <= 18.0:\n",
    "                    return 21.799\n",
    "                else:\n",
    "                    return 24.005\n",
    "            else:\n",
    "                if sen_hou <= 8.4:\n",
    "                    return 20.518\n",
    "                else:\n",
    "                    return 21.073\n",
    "        else:\n",
    "            if Temp_mean_m1 <= 22.687:\n",
    "                if Temp_mean_m1 <= 20.928:\n",
    "                    return 22.374\n",
    "                else:\n",
    "                    return 23.759\n",
    "            else:\n",
    "                if Temp_mean_p0 <= 27.436:\n",
    "                    return 27.003\n",
    "                else:\n",
    "                    return 23.155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.load('states_n.npy')\n",
    "actions = np.load('actions_n.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2_feature_names = ['Temp_mean_p0','Temp_mean_m1','sen_hou','temp_OA_0','temp_OA_1','rh','rtp_0','rtp_1','rtp_2','rtp_3','rtp_4','rtp_5','rtp_6']\n",
    "\n",
    "def batt_state_rbc(hours,rtp_0,rtp_1,rtp_2):\n",
    "    if rtp_2>0.2 or rtp_1>0.2: \n",
    "        batt_act = 1.0       \n",
    "    else:\n",
    "        batt_act = 0           \n",
    "    if hours>15:\n",
    "        batt_act = 0.5 \n",
    "\n",
    "    if rtp_0 >0.25:\n",
    "        batt_act = -1  \n",
    "\n",
    "    if hours>14:\n",
    "        batt_act = 1 \n",
    "\n",
    "    return batt_act \n",
    "\n",
    "\n",
    "building_id=1\n",
    "\n",
    "min_max = {}\n",
    "\n",
    "min_max['sen_hou'] = [0,24]\n",
    "min_max['temp_OA'] = [-20,40]\n",
    "min_max['rh_OA'] = [0,100]\n",
    "min_max['Temp_mean_p0'] = [15,30]; min_max['Temp_mean_m1'] = [15,30]\n",
    "min_max['sen_hou'] = [0,24]\n",
    "min_max['hir_sol'] = [0,700] \n",
    "\n",
    "if building_id == 1: \n",
    "    data = '0_Data/Case_1/comb_data.csv'\n",
    "    min_max[\"hvac_dem_tot\"] = [0,6020] #1  #kW \n",
    "    min_max['appliances_pow'] = [0,42] #1 #kW\n",
    "    min_max['elec_lights'] = [0,70]   #1 #kW\n",
    "    min_max['Occ'] = [0,3300]\n",
    "    min_max['batt_cap'] = [0,6000] \n",
    "    min_max['rtp'] = [0.05,0.3]\n",
    "    min_max['soc'] = [0,1]\n",
    "    scale_delta, scale_hvac = 200 , 200\n",
    "elif building_id == 6:\n",
    "    data = '0_Data/Case_6/comb_data.csv'\n",
    "    min_max[\"hvac_dem_tot\"] = [0,1620] #6  #kW \n",
    "    min_max['appliances_pow'] = [0,160] #6 #kW\n",
    "    min_max['elec_lights'] = [0,190]   #6 #kW\n",
    "    min_max['Occ'] = [0,250]\n",
    "    scale_delta, scale_hvac = 600 , 200\n",
    "\n",
    "\n",
    "min_max['u_heat_stp'] = [15,25] \n",
    "min_max['u_cool_stp'] = [20,30] \n",
    "min_max['delta_T'] = [0,1] \n",
    "min_max['Stp_n'] = [0,1] \n",
    "min_max['mode'] = [0,1] \n",
    "\n",
    "\n",
    "def weights_init_(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class GaussianPolicy(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim, action_space=None):\n",
    "        super(GaussianPolicy, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_dim[0])\n",
    "        self.linear2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
    "        print (hidden_dim[2])\n",
    "        print (num_actions)\n",
    "        self.linear3 = nn.Linear(hidden_dim[1], hidden_dim[2])\n",
    "\n",
    "        self.mean_linear = nn.Linear(hidden_dim[2], num_actions)\n",
    "        self.log_std_linear = nn.Linear(hidden_dim[2], num_actions)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "        # action rescaling\n",
    "        if action_space is None:\n",
    "            self.action_scale = torch.tensor(1.)\n",
    "            self.action_bias = torch.tensor(0.)\n",
    "        else:\n",
    "            self.action_scale = torch.FloatTensor(\n",
    "                (action_space.high - action_space.low) / 2.)\n",
    "            self.action_bias = torch.FloatTensor(\n",
    "                (action_space.high + action_space.low) / 2.)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        mean = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, min=LOG_SIG_MIN, max=LOG_SIG_MAX)\n",
    "        return mean, log_std\n",
    "\n",
    "    def sample(self, state):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        normal = Normal(mean, std)\n",
    "        x_t = normal.rsample()  # for reparameterization trick (mean + std * N(0,1))\n",
    "        y_t = torch.tanh(x_t)\n",
    "        action = y_t * self.action_scale + self.action_bias\n",
    "        log_prob = normal.log_prob(x_t)\n",
    "        # Enforcing Action Bound\n",
    "        log_prob -= torch.log(self.action_scale * (1 - y_t.pow(2)) + epsilon)\n",
    "        log_prob = log_prob.sum(1, keepdim=True)\n",
    "        mean = torch.tanh(mean) * self.action_scale + self.action_bias\n",
    "        return action, log_prob, mean\n",
    "\n",
    "    def to(self, device):\n",
    "        self.action_scale = self.action_scale.to(device)\n",
    "        self.action_bias = self.action_bias.to(device)\n",
    "        return super(GaussianPolicy, self).to(device)\n",
    "\n",
    "\n",
    "class DeterministicPolicy(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim, action_space=None):\n",
    "        super(DeterministicPolicy, self).__init__()\n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.mean = nn.Linear(hidden_dim, num_actions)\n",
    "        self.noise = torch.Tensor(num_actions)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "        # action rescaling\n",
    "        if action_space is None:\n",
    "            self.action_scale = 1.\n",
    "            self.action_bias = 0.\n",
    "        else:\n",
    "            self.action_scale = torch.FloatTensor(\n",
    "                (action_space.high - action_space.low) / 2.)\n",
    "            self.action_bias = torch.FloatTensor(\n",
    "                (action_space.high + action_space.low) / 2.)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mean = torch.tanh(self.mean(x)) * self.action_scale + self.action_bias\n",
    "        return mean\n",
    "\n",
    "    def sample(self, state):\n",
    "        mean = self.forward(state)\n",
    "        noise = self.noise.normal_(0., std=0.1)\n",
    "        noise = noise.clamp(-0.25, 0.25)\n",
    "        action = mean + noise\n",
    "        return action, torch.tensor(0.), mean\n",
    "\n",
    "    def to(self, device):\n",
    "        self.action_scale = self.action_scale.to(device)\n",
    "        self.action_bias = self.action_bias.to(device)\n",
    "        self.noise = self.noise.to(device)\n",
    "        return super(DeterministicPolicy, self).to(device)\n",
    "    \n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "\n",
    "        # Q1 architecture\n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_dim[0])\n",
    "        self.linear2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
    "        self.linear3 = nn.Linear(hidden_dim[1], hidden_dim[2])\n",
    "        self.linear4 = nn.Linear(hidden_dim[2], 1)\n",
    "\n",
    "        # Q2 architecture\n",
    "        self.linear5 = nn.Linear(num_inputs + num_actions, hidden_dim[0])\n",
    "        self.linear6 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
    "        self.linear7 = nn.Linear(hidden_dim[1], hidden_dim[2])\n",
    "        self.linear8 = nn.Linear(hidden_dim[2], 1)\n",
    "\n",
    "        self.apply(weights_init_)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        xu = torch.cat([state, action], 1)\n",
    "        \n",
    "        x1 = F.relu(self.linear1(xu))\n",
    "        x1 = F.relu(self.linear2(x1))\n",
    "        x1 = F.relu(self.linear3(x1))\n",
    "        x1 = self.linear4(x1)\n",
    "\n",
    "        x2 = F.relu(self.linear5(xu))\n",
    "        x2 = F.relu(self.linear6(x2))\n",
    "        x2 = F.relu(self.linear7(x2))\n",
    "        x2 = self.linear8(x2)\n",
    "\n",
    "        return x1, x2\n",
    "    \n",
    "\n",
    "def e_load_checkpoint(ckpt_path, evaluate=False):       \n",
    "    checkpoint = torch.load(ckpt_path)    \n",
    "    e_policy.load_state_dict(checkpoint['policy_state_dict'])\n",
    "    e_critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "    e_critic_target.load_state_dict(checkpoint['critic_target_state_dict'])\n",
    "    e_critic_optim.load_state_dict(checkpoint['critic_optimizer_state_dict'])\n",
    "    e_policy_optim.load_state_dict(checkpoint['policy_optimizer_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "e_obs_shape =  10 \n",
    "e_act_shape = 2 \n",
    "\n",
    "e_policy = GaussianPolicy(e_obs_shape, e_act_shape, args['hidden_size'], None).to(device)\n",
    "e_critic_target = QNetwork(e_obs_shape, e_act_shape, args['hidden_size']).to(device)\n",
    "e_critic = QNetwork(e_obs_shape, e_act_shape, args['hidden_size']).to(device=device)\n",
    "e_critic_optim = Adam(e_critic.parameters(), lr=args['lr'])\n",
    "e_policy_optim = Adam(e_policy.parameters(), lr=args['lr'])\n",
    "\n",
    "# qf1_next_target, qf2_next_target = e_critic_target(next_state_batch, next_state_action)\n",
    "# qf1, qf2 = e_critic(state_batch, action_batch) \n",
    "\n",
    "# qf1_loss = F.mse_loss(qf1, next_q_value) \n",
    "# qf2_loss = F.mse_loss(qf2, next_q_value)\n",
    "# qf_loss = qf1_loss + qf2_loss\n",
    "\n",
    "# e_critic_optim.zero_grad()\n",
    "# qf_loss.backward()\n",
    "# e_critic_optim.step()\n",
    "\n",
    "# e_load_checkpoint(ckpt_path=, evaluate=False)\n",
    "\n",
    "\n",
    "def init_rtp():\n",
    "    rng = np.random.default_rng()\n",
    "    price_rand = rng.uniform(size=(1, 24), low=0.16, high=0.25)[0]*0.8\n",
    "    # print (\"init_price:{}\".format(price_rand))\n",
    "    # print ()\n",
    "    rtp = [0] * 24\n",
    "    rtp[0] = price_rand[0]* np.random.uniform(0.5,0.7)  # 0-1\n",
    "    rtp[1] = price_rand[1]* np.random.uniform(0.6,0.8)     # 1-2\n",
    "    rtp[2] = price_rand[2]* np.random.uniform(0.6,0.8)      # 2-3\n",
    "    rtp[3] = price_rand[3]* np.random.uniform(0.7,0.9)     # 3-4\n",
    "    rtp[4] = price_rand[4]* np.random.uniform(0.7,0.9)       # 4-5\n",
    "    rtp[5] = price_rand[5]* np.random.uniform(0.7,0.9)     # 5-6\n",
    "    rtp[6] = price_rand[6]* np.random.uniform(0.7,0.9)       # 6-7\n",
    "    rtp[7] = price_rand[7]* np.random.uniform(0.8,1.0)       # 7-8\n",
    "    rtp[8] = price_rand[8]* np.random.uniform(0.8,1.0)       # 8-9\n",
    "    rtp[9] = price_rand[9]* np.random.uniform(0.9,1.1)       # 9-10\n",
    "    rtp[10]= price_rand[10]* np.random.uniform(0.9,1.2)       # 10-11\n",
    "    rtp[11]= price_rand[11]* np.random.uniform(1.0,1.4)       # 11-12           \n",
    "    rtp[12]= price_rand[12]* np.random.uniform(1.5,1.8)       # 12-13\n",
    "    rtp[13]= price_rand[13]* np.random.uniform(1.8,2.2)       # 13-14\n",
    "    rtp[14]= price_rand[14]* np.random.uniform(1.8,2.5)      # 14-15\n",
    "    rtp[15]= price_rand[15]* np.random.uniform(1.5,2.2)       # 15-16\n",
    "    rtp[16]= price_rand[16]* np.random.uniform(1.5,1.9)       # 16-17\n",
    "    rtp[17]= price_rand[17]* np.random.uniform(1.0,1.5)       # 17-18\n",
    "    rtp[18]= price_rand[18]* np.random.uniform(1.0,1.3)       #18-19\n",
    "    rtp[19]= price_rand[19]* np.random.uniform(0.9,1.3)      # 19-20\n",
    "    rtp[20]= price_rand[20]* np.random.uniform(0.9,1.2)       # 20-21\n",
    "    rtp[21]= price_rand[21]* np.random.uniform(0.7,1.0)       # 21-22\n",
    "    rtp[22]= price_rand[22]* np.random.uniform(0.5,0.7)       # 22-23\n",
    "    rtp[23]= price_rand[23]* np.random.uniform(0.5,0.7)        #23-24\n",
    "    # print (rtp)\n",
    "    return rtp \n",
    "\n",
    "def get_rtp_price(rtp,hour):\n",
    "    index = int(math.floor(hour))\n",
    "    return rtp[index]\n",
    "\n",
    "def round_down_to_half(n):\n",
    "    return int(2 * n) / 2\n",
    "\n",
    "\n",
    "def get_sol(sen_hou):\n",
    "     # Parameters for the bell-shaped distribution\n",
    "     peak_time = np.random.uniform(11,13)  # Peak at noon (12:00 PM)\n",
    "     peak_value = np.random.uniform(200,700)/0.4\n",
    "     std_deviation = 1.0  # Standard deviation\n",
    "     # Calculate the corresponding values using a normal distribution\n",
    "     bell_value = peak_value * norm.pdf(sen_hou, loc=peak_time, scale=std_deviation)\n",
    "\n",
    "     return bell_value\n",
    "\n",
    "def init_capacity_ev():\n",
    "    no_of_occ = 3300\n",
    "    percentage = 0.05\n",
    "\n",
    "    ev_owners = int(no_of_occ*percentage)\n",
    "\n",
    "    ev_data = pd.DataFrame(columns=['owner_no','capacity','start_time','end_time','start_soc','end_demand'])\n",
    "    numbers = [20, 30, 40, 70, 100,120]\n",
    "    probabilities = [0.25, 0.35, 0.25, 0.10,0.03,0.02]\n",
    "\n",
    "    start_list =      [   6, 6.5, 7.0,7.5, 8.0, 8.5,    9,  9.5,   10,   11,   12, 13,   14]\n",
    "    prob_start_list = [0.03,0.04,0.04,0.2, 0.4, 0.1, 0.05, 0.04, 0.035, 0.025, 0.02,0.01,0.01] \n",
    "\n",
    "    end_list =      [  13, 13.5, 14, 14.5,   15, 15.5,   16, 16.5,   17, 17.5, 18, 18.5, 19.0, 19.5, 20, 20.5,  21, 21.5, 22, 23, 24]\n",
    "    prob_end_list = [ 0.5,  1.5,  1,    2,  3, 5,  6,  6, 20, 20,  12,   12,  4,  2.5,   1.25,   1, 1,  0.5, 0.5, 0.25,0]\n",
    "    prob_end_list = [x/100 for x in prob_end_list]\n",
    "\n",
    "    \n",
    "    for owner in range(ev_owners):\n",
    "        cap = np.random.choice(numbers,p=probabilities)\n",
    "        new_row = {'owner_no':owner, 'capacity':cap,\n",
    "                'start_time':np.random.choice(start_list,p=prob_start_list),\n",
    "                'end_time':np.random.choice(end_list,p=prob_end_list),\n",
    "                'start_soc': np.random.uniform(low=0.05,high=0.35)*cap,\n",
    "                'end_demand': np.random.uniform(low=0.95,high=0.100)*cap\n",
    "                }     \n",
    "        # print (new_row)\n",
    "        ev_data = pd.concat([ev_data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    ev_data['discharge'] = ev_data['capacity']/5  \n",
    "    ev_data['charge'] = ev_data['capacity']/3  \n",
    "    times = np.arange(0, 24.5, 0.5).tolist()\n",
    "    capacity_per_time = {time: ev_data.loc[(ev_data['start_time'] < time) & (ev_data['end_time'] >= time), 'capacity'].sum() for time in times}\n",
    "    return capacity_per_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20757852464477722,\n",
       " 0.18777232096480959,\n",
       " 0.5875667941038116,\n",
       " 0.7680248812883541,\n",
       " 0.7868818037957932,\n",
       " 0.5986735814677058,\n",
       " 0.946055141479575,\n",
       " 1.3141238925383127,\n",
       " 0.9686257885056884,\n",
       " 0.5495520199154447]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_state_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.4535]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_n[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20757852464477722,\n",
       " 0.18777232096480959,\n",
       " 0.5875667941038116,\n",
       " 0.7680248812883541,\n",
       " 0.7868818037957932,\n",
       " 0.5986735814677058,\n",
       " 0.946055141479575,\n",
       " 1.3141238925383127,\n",
       " 0.9686257885056884,\n",
       " 0.5495520199154447]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_state_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\02_Daedo\\01_Git\\01_Gym\\15a_F_alien\\15_Forecasting\\02e_extract_and_train_rules.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m qf1_target, qf2_target \u001b[39m=\u001b[39m e_critic_target(torch\u001b[39m.\u001b[39;49mtensor(e_state_n), torch\u001b[39m.\u001b[39;49mtensor(action_n[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m qf1, qf2 \u001b[39m=\u001b[39m e_critic([e_state_n], [action_n[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\didso\\.conda\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\didso\\.conda\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32md:\\OneDrive\\02_Daedo\\01_Git\\01_Gym\\15a_F_alien\\15_Forecasting\\02e_extract_and_train_rules.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X22sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, state, action):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X22sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m     xu \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([state, action], \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X22sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m     x1 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(xu))\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X22sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m     x1 \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(x1))\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "\n",
    "qf1_target, qf2_target = e_critic_target(torch.tensor(e_state_n), torch.tensor(action_n[:-1]))\n",
    "qf1, qf2 = e_critic([e_state_n], [action_n[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08751500103558234,\n",
       " 0.10653704256122012,\n",
       " 0.11524449977515756,\n",
       " 0.15130308411854804,\n",
       " 0.10680556224359292,\n",
       " 0.14714899907507067,\n",
       " 0.16368932152832555,\n",
       " 0.15583386704391358,\n",
       " 0.1351305394119396,\n",
       " 0.18845739336450776,\n",
       " 0.15930946918151057,\n",
       " 0.1717825940362129,\n",
       " 0.32255877455480175,\n",
       " 0.31702914490225975,\n",
       " 0.2896163462830814,\n",
       " 0.2765827269219346,\n",
       " 0.23576420889802613,\n",
       " 0.16128213248139606,\n",
       " 0.19792982003877577,\n",
       " 0.14010780007953794,\n",
       " 0.190937969620207,\n",
       " 0.16121864707697425,\n",
       " 0.11300001190286886,\n",
       " 0.10199401399463126]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtp = init_rtp()\n",
    "rtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\didso\\AppData\\Local\\Temp\\ipykernel_18016\\771987519.py:102: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  ev_data = pd.concat([ev_data, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\02_Daedo\\01_Git\\01_Gym\\15a_F_alien\\15_Forecasting\\02e_extract_and_train_rules.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m      clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m      rtp \u001b[39m=\u001b[39m init_rtp()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m      capacity_per_time \u001b[39m=\u001b[39m  init_capacity_ev()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m Temp_mean_p0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m17\u001b[39m,\u001b[39m28\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m Temp_mean_m1 \u001b[39m=\u001b[39m Temp_mean_p0 \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m)\n",
      "\u001b[1;32md:\\OneDrive\\02_Daedo\\01_Git\\01_Gym\\15a_F_alien\\15_Forecasting\\02e_extract_and_train_rules.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     new_row \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mowner_no\u001b[39m\u001b[39m'\u001b[39m:owner, \u001b[39m'\u001b[39m\u001b[39mcapacity\u001b[39m\u001b[39m'\u001b[39m:cap,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mstart_time\u001b[39m\u001b[39m'\u001b[39m:np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(start_list,p\u001b[39m=\u001b[39mprob_start_list),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mend_time\u001b[39m\u001b[39m'\u001b[39m:np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(end_list,p\u001b[39m=\u001b[39mprob_end_list),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mstart_soc\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(low\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m,high\u001b[39m=\u001b[39m\u001b[39m0.35\u001b[39m)\u001b[39m*\u001b[39mcap,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mend_demand\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(low\u001b[39m=\u001b[39m\u001b[39m0.95\u001b[39m,high\u001b[39m=\u001b[39m\u001b[39m0.100\u001b[39m)\u001b[39m*\u001b[39mcap\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m             }     \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     \u001b[39m# print (new_row)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     ev_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([ev_data, pd\u001b[39m.\u001b[39;49mDataFrame([new_row])], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m ev_data[\u001b[39m'\u001b[39m\u001b[39mdischarge\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ev_data[\u001b[39m'\u001b[39m\u001b[39mcapacity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m5\u001b[39m  \n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/OneDrive/02_Daedo/01_Git/01_Gym/15a_F_alien/15_Forecasting/02e_extract_and_train_rules.ipynb#X16sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m ev_data[\u001b[39m'\u001b[39m\u001b[39mcharge\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ev_data[\u001b[39m'\u001b[39m\u001b[39mcapacity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m3\u001b[39m  \n",
      "File \u001b[1;32mc:\\Users\\didso\\.conda\\envs\\torch\\Lib\\site-packages\\pandas\\core\\frame.py:817\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    808\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    809\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    810\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    811\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    815\u001b[0m         dtype,\n\u001b[0;32m    816\u001b[0m     )\n\u001b[1;32m--> 817\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    818\u001b[0m         arrays,\n\u001b[0;32m    819\u001b[0m         columns,\n\u001b[0;32m    820\u001b[0m         index,\n\u001b[0;32m    821\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    822\u001b[0m         typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    823\u001b[0m     )\n\u001b[0;32m    824\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    825\u001b[0m     mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    826\u001b[0m         data,\n\u001b[0;32m    827\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    831\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    832\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\didso\\.conda\\envs\\torch\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[39m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[39mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    153\u001b[0m         arrays, axes, consolidate\u001b[39m=\u001b[39;49mconsolidate, refs\u001b[39m=\u001b[39;49mrefs\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[39melif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\didso\\.conda\\envs\\torch\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2086\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2069\u001b[0m     arrays: \u001b[39mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2070\u001b[0m     axes: \u001b[39mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[39m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2083\u001b[0m     \u001b[39m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2085\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2086\u001b[0m         blocks \u001b[39m=\u001b[39m _form_blocks(arrays, consolidate, refs)\n\u001b[0;32m   2087\u001b[0m         mgr \u001b[39m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2088\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\didso\\.conda\\envs\\torch\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2160\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtype\u001b[39m.\u001b[39mtype, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m)):\n\u001b[0;32m   2158\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39mobject\u001b[39m)\n\u001b[1;32m-> 2160\u001b[0m values, placement \u001b[39m=\u001b[39m _stack_arrays(\u001b[39mlist\u001b[39;49m(tup_block), dtype)\n\u001b[0;32m   2161\u001b[0m \u001b[39mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2162\u001b[0m     values \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Users\\didso\\.conda\\envs\\torch\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2202\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2200\u001b[0m stacked \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(shape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m   2201\u001b[0m \u001b[39mfor\u001b[39;00m i, arr \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arrays):\n\u001b[1;32m-> 2202\u001b[0m     stacked[i] \u001b[39m=\u001b[39m arr\n\u001b[0;32m   2204\u001b[0m \u001b[39mreturn\u001b[39;00m stacked, placement\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sample generation \n",
    "n_samples = 50000\n",
    "cnt =0 \n",
    "actions_n = []\n",
    "states_n = [] \n",
    "e_states_n = [] \n",
    "e_critic_q = [] \n",
    "e_critic_target_q = []\n",
    "\n",
    "check = []\n",
    "\n",
    "for iteration in range(n_samples):     \n",
    "\n",
    "     print (iteration)\n",
    "\n",
    "     if iteration%100==0:\n",
    "          clear_output(wait=True)\n",
    "          rtp = init_rtp()\n",
    "          capacity_per_time =  init_capacity_ev()\n",
    "\n",
    "     Temp_mean_p0 = np.random.uniform(17,28)\n",
    "     Temp_mean_m1 = Temp_mean_p0 + np.random.uniform(-3,3)\n",
    "     if np.random.uniform(0,1)<0.6:\n",
    "          sen_hou = np.random.uniform(0,24)\n",
    "     else:\n",
    "          sen_hou = np.random.uniform(11,13)\n",
    "     if sen_hou<6 and sen_hou>18:\n",
    "          temp_OA_0 = np.random.uniform(16,26)\n",
    "     else:\n",
    "          temp_OA_0 = np.random.uniform(20,35)\n",
    "     temp_OA_1 =  temp_OA_0 + np.random.uniform(-2,2)\n",
    "     rh_OA = np.random.uniform(40,95)\n",
    "     hir_sol_0 = get_sol(sen_hou)\n",
    "     hir_sol_1 = get_sol((sen_hou+1)%24)\n",
    "     rtp_0 = get_rtp_price(rtp,sen_hou) # rtp\n",
    "     rtp_1 = get_rtp_price(rtp,(sen_hou+1)%24) # rtp\n",
    "     rtp_2 = get_rtp_price(rtp,(sen_hou+2)%24) # rtp \n",
    "     rtp_3 = get_rtp_price(rtp,(sen_hou+3)%24) # rtp \n",
    "     ev_0 = capacity_per_time[round_down_to_half((sen_hou+0)%24)]\n",
    "     ev_1 = capacity_per_time[round_down_to_half((sen_hou+0.5)%24)]\n",
    "     ev_2 = capacity_per_time[round_down_to_half((sen_hou+1.0)%24)]\n",
    "     ev_3 = capacity_per_time[round_down_to_half((sen_hou+1.5)%24)]\n",
    "     ev_4 = capacity_per_time[round_down_to_half((sen_hou+2.0)%24)]\n",
    "     soc = np.random.uniform(0,1)\n",
    "     \n",
    "\n",
    "     htp = 15\n",
    "     clg = cool_stp(Temp_mean_p0,Temp_mean_m1,sen_hou,rh_OA,rtp_2)\n",
    "     batt = batt_state_rbc(sen_hou,rtp_0,rtp_1,rtp_2)\n",
    "\n",
    "     action = [htp,clg,batt] \n",
    "\n",
    "     state = [Temp_mean_p0,Temp_mean_m1,sen_hou,temp_OA_0,temp_OA_1,rh_OA,hir_sol_0,hir_sol_1,\n",
    "          rtp_0,rtp_1,rtp_2,rtp_3,\n",
    "          ev_0,ev_1,ev_2,ev_3,ev_4,soc]\n",
    "\n",
    "     keys  = ['Temp_mean_p0','Temp_mean_m1','sen_hou','temp_OA','temp_OA','rh_OA','hir_sol','hir_sol',\n",
    "          'rtp','rtp','rtp','rtp',\n",
    "          'batt_cap','batt_cap','batt_cap','batt_cap','batt_cap','soc']\n",
    "     act_keys = ['u_heat_stp','u_cool_stp','soc']\n",
    "     e_state_keys = ['Temp_mean_p0','Temp_mean_m1','sen_hou','temp_OA','temp_OA','rh_OA','rtp','rtp','rtp','rtp']\n",
    "\n",
    "     earlier_state = [Temp_mean_p0,Temp_mean_m1,sen_hou,temp_OA_0,temp_OA_1,rh_OA,rtp_0,rtp_1,rtp_2,rtp_3]\n",
    "\n",
    "          \n",
    "     state_n,action_n,e_state_n = [],[],[]\n",
    "     for index,val in enumerate(state):\n",
    "          # print (index)\n",
    "          val_n  =  (val - min_max[keys[index]][0])/(min_max[keys[index]][1]-min_max[keys[index]][0])\n",
    "          state_n.append(val_n)\n",
    "\n",
    "     for index,val in enumerate(action):\n",
    "          # print (index)\n",
    "          act_val_n  =  (val - min_max[act_keys[index]][0])/(min_max[act_keys[index]][1]-min_max[act_keys[index]][0])\n",
    "          action_n.append(act_val_n)\n",
    "\n",
    "     for index,val in enumerate(earlier_state):\n",
    "          # print (index)\n",
    "          e_state_n_val_n  =  (val - min_max[e_state_keys[index]][0])/(min_max[e_state_keys[index]][1]-min_max[e_state_keys[index]][0])\n",
    "          e_state_n.append(e_state_n_val_n)\n",
    "\n",
    "     if rtp_0 > 0.25:\n",
    "          cnt +=1\n",
    "          check.append([state,action])\n",
    "\n",
    "     # print (torch.tensor([e_state_n]))\n",
    "     # print (torch.tensor([action_n[:-1]]))\n",
    "\n",
    "     # qf1_target, qf2_target = e_critic_target(torch.tensor(e_state_n), torch.tensor(action_n[:-1]))\n",
    "     # qf1, qf2 = e_critic([e_state_n], [action_n[:-1]]) \n",
    "     \n",
    "     actions_n.append(action_n)\n",
    "     states_n.append(state_n)\n",
    "     # e_states_n.append(e_state_n)\n",
    "     # e_critic_target_q.append([qf1_target,qf2_target])\n",
    "     # e_critic_q.append([qf1,qf2])\n",
    "\n",
    "np.save('actions_n.npy', np.array(actions_n)); np.save('states_n.npy', np.array(states_n))\n",
    "# np.save('e_states_n.npy', np.array(e_states_n))\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_samples(no_samples):\n",
    "    # Create a list of indices to sample from\n",
    "    indices = list(range(len(states)))\n",
    "\n",
    "    # Randomly shuffle the indices\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # Sample 40 elements with the same index from both arrays\n",
    "    sampled_states = [states[i] for i in indices[:no_samples]]\n",
    "    sampled_actions = [actions[i] for i in indices[:no_samples]]\n",
    "    return sampled_states,sampled_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, init_w=3e-3, log_std_min=-20, log_std_max=2):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        hidden_size = args['hidden_size']\n",
    "        self.log_std_min = log_std_min\n",
    "        self.log_std_max = log_std_max\n",
    "                     \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size[0])\n",
    "        self.linear2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.linear3 = nn.Linear(hidden_size[1], hidden_size[2])\n",
    "        \n",
    "        self.mean_linear = nn.Linear(hidden_size[2], num_actions)\n",
    "\n",
    "        self.mean_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.mean_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "        self.log_std_linear = nn.Linear(hidden_size[2], num_actions)\n",
    "\n",
    "        self.log_std_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.log_std_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        \n",
    "        mean    = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)\n",
    "        \n",
    "        return mean, log_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np ; import random\n",
    "import gym; from gym import spaces\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didso\\.conda\\envs\\torch\\Lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "building_obs = ['Temp_mean_p0','Temp_mean_m1','sen_hou']\n",
    "forecast_obs = {'temp_OA': [0,1],'rh_OA':[0],'hir_sol':{0,1}} \n",
    "price_struct = \"rtp\" \n",
    "price_obs = [0,1,2,3]\n",
    "ev_avail_obs = [0,0.5,1.0,1.5,2.0]\n",
    "state_dim_sac = len(building_obs) + sum(len(v) for v in forecast_obs.values()) + len(price_obs) + len(ev_avail_obs) + 1 \n",
    "\n",
    "print (state_dim_sac)\n",
    "sac_act_lower_bnds = [0,0,-1]; sac_act_upper_bnds = [1,1,1]\n",
    "\n",
    "sac_obs_lower_bnds = np.zeros(state_dim_sac); sac_obs_upper_bnds = np.ones(state_dim_sac)\n",
    "\n",
    "custom_observation_space = spaces.Box(low = sac_obs_lower_bnds,\n",
    "                                       high = sac_obs_upper_bnds,\n",
    "                                       dtype= np.float32) \n",
    "custom_action_space = spaces.Box(low  = np.array(sac_act_lower_bnds),\n",
    "                                       high = np.array(sac_act_upper_bnds),\n",
    "                                       dtype= np.float32) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000, 1600, 1000]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23959322, 0.10779197, 0.15540407, ..., 0.        , 0.        ,\n",
       "        0.20415929],\n",
       "       [0.55805489, 0.46549609, 0.40046877, ..., 1.03166667, 1.03833333,\n",
       "        0.53014471],\n",
       "       [0.46845386, 0.42076814, 0.0231451 , ..., 0.        , 0.        ,\n",
       "        0.58233262],\n",
       "       ...,\n",
       "       [0.45740227, 0.40247397, 0.16756567, ..., 0.        , 0.        ,\n",
       "        0.74428309],\n",
       "       [0.54794202, 0.41060694, 0.86837179, ..., 0.01166667, 0.00833333,\n",
       "        0.96812987],\n",
       "       [0.41629326, 0.46580431, 0.07974822, ..., 0.        , 0.        ,\n",
       "        0.19979441]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "policy = GaussianPolicy(custom_observation_space.shape[0], 3, args['hidden_size'], custom_action_space).to(device)\n",
    "critic_target = QNetwork(custom_observation_space.shape[0], 3, args['hidden_size']).to(device)\n",
    "critic = QNetwork(custom_observation_space.shape[0], 3, args['hidden_size']).to(device=device)\n",
    "critic_optim = Adam(critic.parameters(), lr=args['lr'])\n",
    "policy_optim = Adam(policy.parameters(), lr=args['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(ckpt_path, evaluate=False):       \n",
    "    checkpoint = torch.load(ckpt_path)    \n",
    "    policy.load_state_dict(checkpoint['policy_state_dict'])\n",
    "    critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "    critic_target.load_state_dict(checkpoint['critic_target_state_dict'])\n",
    "    critic_optim.load_state_dict(checkpoint['critic_optimizer_state_dict'])\n",
    "    policy_optim.load_state_dict(checkpoint['policy_optimizer_state_dict'])\n",
    "\n",
    "def save_checkpoint(ckpt_path=None):\n",
    "    torch.save({'policy_state_dict': policy.state_dict(),\n",
    "                'critic_state_dict': critic.state_dict(),\n",
    "                'critic_target_state_dict': critic_target.state_dict(),\n",
    "                'critic_optimizer_state_dict': critic_optim.state_dict(),\n",
    "                'policy_optimizer_state_dict': policy_optim.state_dict()}, ckpt_path)\n",
    "\n",
    "path_NN = '0_Data/Case_1d/02_NN/'\n",
    "save_checkpoint(ckpt_path=path_NN+\"checkpoints/sac_checkpoint_\"+str(0)+\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "policy_lr = 0.0001\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=policy_lr)\n",
    "ckpt_path = path_NN+\"checkpoints/sac_checkpoint_\"+str(0)+\"_\"\n",
    "# checkpoint = torch.load(ckpt_path)\n",
    "\n",
    "# Prepare the data\n",
    "load_checkpoint(ckpt_path=path_NN+\"checkpoints/sac_checkpoint_\"+str(0)+\"_\")\n",
    "\n",
    "\"\"\"alternate \"\"\"\n",
    "# X = torch.randn(n, 9)\n",
    "# y = torch.randn(n, 2)\n",
    "sample_gen_iter =50\n",
    "# Training loop\n",
    "\n",
    "for i in range(sample_gen_iter):\n",
    "    sampled_states,sampled_actions = gen_samples(1000)\n",
    "    X = torch.FloatTensor(sampled_states)\n",
    "    y = torch.FloatTensor(sampled_actions)\n",
    "    print (\"gen new data\")\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        action, _, _ = policy.sample(X)\n",
    "        y_pred = action\n",
    "        # y_pred = model(X)\n",
    "        # print (\"y_true: {};y_pred: {}\".format(y,y_pred))\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "        print (i)\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        clear_output(wait=True)\n",
    "        print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_NN = '0_Data/Case_1d/02_NN/'\n",
    "save_checkpoint(ckpt_path=path_NN+\"checkpoints/sac_checkpoint_\"+str(0)+\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(states)\n",
    "y = torch.FloatTensor(actions)\n",
    "action, _, _ = policy.sample(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 'g'),\n",
       " (5, 'e'),\n",
       " (10, 'j'),\n",
       " (1, 'a'),\n",
       " (3, 'c'),\n",
       " (4, 'd'),\n",
       " (6, 'f'),\n",
       " (9, 'i'),\n",
       " (2, 'b'),\n",
       " (8, 'h')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rbc_case4c(sen_hou,rtp_0,rtp_1,rtp_2):\n",
    "     htg = 15 \n",
    "     if sen_hou>6 and sen_hou<19: \n",
    "          clg = 24\n",
    "          if rtp_2>0.2:\n",
    "              clg = 21 \n",
    "          \n",
    "          if rtp_0>0.25:\n",
    "              clg = 24.5 \n",
    "     else: \n",
    "          clg = 30 \n",
    "\n",
    "     batt_act = batt_state_rbc(sen_hou,rtp_0,rtp_1,rtp_2)\n",
    "\n",
    "     return [htg,clg,batt_act]\n",
    "\n",
    "\n",
    "def batt_state_rbc(hours,rtp_0,rtp_1,rtp_2):\n",
    "    if rtp_2>0.2 or rtp_1>0.2: \n",
    "        batt_act = 1.0       \n",
    "    else:\n",
    "        batt_act = 0           \n",
    "    if hours>15:\n",
    "        batt_act = 0.5 \n",
    "\n",
    "    if rtp_0 >0.25:\n",
    "        batt_act = -1  \n",
    "\n",
    "    if hours>14:\n",
    "        batt_act = 1 \n",
    "\n",
    "    return batt_act "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "array2 = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41707928, 0.25847605, 0.44464433, ..., 1.02      , 1.02      ,\n",
       "       0.29238616])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\didso\\AppData\\Local\\Temp\\ipykernel_68060\\504638642.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  X = torch.FloatTensor(sampled_states)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _, _ = policy.sample(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
